{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input and Output\n",
    "\n",
    "Xarray supports direct serialization and I/O to several file formats including pickle, netCDF, OPeNDAP (read-only), GRIB1/2 (read-only), and HDF by integrating with third-party libraries. Additional serialization formats for 1-dimensional data are available through pandas.\n",
    "\n",
    "File types\n",
    "- Pickle\n",
    "- NetCDF 3/4\n",
    "- RasterIO\n",
    "- Zarr\n",
    "- PyNio\n",
    "\n",
    "Interoperability\n",
    "- Pandas\n",
    "- Iris\n",
    "- CDMS\n",
    "- dask DataFrame\n",
    "\n",
    "### Tutorial Duriation\n",
    "10 minutes\n",
    "\n",
    "### Going Further\n",
    "\n",
    "Xarray I/O Documentation: http://xarray.pydata.org/en/latest/io.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 36, x: 275, y: 205)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1980-09-16T12:00:00 1980-10-17 ...\n",
       "    xc       (y, x) float64 189.2 189.4 189.6 189.7 189.9 190.1 190.2 190.4 ...\n",
       "    yc       (y, x) float64 16.53 16.78 17.02 17.27 17.51 17.76 18.0 18.25 ...\n",
       "Dimensions without coordinates: x, y\n",
       "Data variables:\n",
       "    Tair     (time, y, x) float64 nan nan nan nan nan nan nan nan nan nan ...\n",
       "Attributes:\n",
       "    title:                     /workspace/jhamman/processed/R1002RBRxaaa01a/l...\n",
       "    institution:               U.W.\n",
       "    source:                    RACM R1002RBRxaaa01a\n",
       "    output_frequency:          daily\n",
       "    output_mode:               averaged\n",
       "    convention:                CF-1.4\n",
       "    references:                Based on the initial model of Liang et al., 19...\n",
       "    comment:                   Output from the Variable Infiltration Capacity...\n",
       "    nco_openmp_thread_number:  1\n",
       "    NCO:                       \"4.6.0\"\n",
       "    history:                   Tue Dec 27 14:15:22 2016: ncatted -a dimension..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = xr.tutorial.load_dataset('rasm')  # this actually loads data using xr.open_dataset\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving xarray datasets as netcdf files\n",
    "\n",
    "Xarray provides a high-level method for writing netCDF files directly from Xarray Datasets/DataArrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing data to a netcdf file\n",
    "ds.to_netcdf('./data/rasm.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: ncdump: not found\r\n"
     ]
    }
   ],
   "source": [
    "!ncdump -h ./data/rasm.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening xarray datasets\n",
    "\n",
    "Xarray's `open_dataset` and `open_mfdataset` are the primary functions for opening local or remote datasets such as netCDF, GRIB, OpenDap, and HDF. These operations are all supported by third party libraries (engines) for which xarray provides a common interface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 36, x: 275, y: 205)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1980-09-16T12:00:00 1980-10-17 ...\n",
       "    xc       (y, x) float64 ...\n",
       "    yc       (y, x) float64 ...\n",
       "Dimensions without coordinates: x, y\n",
       "Data variables:\n",
       "    Tair     (time, y, x) float64 ...\n",
       "Attributes:\n",
       "    title:                     /workspace/jhamman/processed/R1002RBRxaaa01a/l...\n",
       "    institution:               U.W.\n",
       "    source:                    RACM R1002RBRxaaa01a\n",
       "    output_frequency:          daily\n",
       "    output_mode:               averaged\n",
       "    convention:                CF-1.4\n",
       "    references:                Based on the initial model of Liang et al., 19...\n",
       "    comment:                   Output from the Variable Infiltration Capacity...\n",
       "    nco_openmp_thread_number:  1\n",
       "    NCO:                       \"4.6.0\"\n",
       "    history:                   Tue Dec 27 14:15:22 2016: ncatted -a dimension..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2 = xr.open_dataset('./data/rasm.nc', engine='netcdf4')\n",
    "ds2\n",
    "\n",
    "# Note that only metadata/coordinates were actually read\n",
    "# The rest of the dataset remains on disk (aka lazy loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ds is not ds2  # they aren't the same dataset\n",
    "assert ds.equals(ds2) # but they are equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Definition*\n",
    "\n",
    "**Roundtrip**: the ability to read/write a dataset without changing its contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multifile datasets\n",
    "\n",
    "Xarray can read/write multifile datasets using the `open_mfdataset` and `save_mfdataset` functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/1980.nc', './data/1981.nc', './data/1982.nc', './data/1983.nc']\n"
     ]
    }
   ],
   "source": [
    "years, datasets = zip(*ds.groupby('time.year'))\n",
    "paths = ['./data/%s.nc' % y for y in years]\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the 4 netcdf files\n",
    "xr.save_mfdataset(datasets, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980.nc  1981.nc  1982.nc  1983.nc  co2.csv  rasm.nc\n",
      "/bin/sh: 1: ncdump: not found\n"
     ]
    }
   ],
   "source": [
    "!ls ./data/\n",
    "!ncdump -h data/1981.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a group of files and concatenate them into a single xarray.Dataset\n",
    "ds3 = xr.open_mfdataset('./data/19*nc')\n",
    "assert ds3.equals(ds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zarr\n",
    "\n",
    "Zarr is a Python package providing an implementation of chunked, compressed, N-dimensional arrays. Zarr has the ability to store arrays in a range of ways, including in memory, in files, and in cloud-based object storage such as Amazon S3 and Google Cloud Storage. Xarrayâ€™s Zarr backend allows xarray to leverage these capabilities.\n",
    "\n",
    "*Note: Zarr support is still an experimental feature. Please report any bugs or unexepected behavior via github issues.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x7fe5c6600128>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zarr\n",
    "ds.to_zarr('./data/rasm.zarr', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tair  time  xc\tyc\n",
      "352K\tdata/rasm.zarr/yc\n",
      "16K\tdata/rasm.zarr/time\n",
      "336K\tdata/rasm.zarr/xc\n",
      "7.7M\tdata/rasm.zarr/Tair\n",
      "8.4M\tdata/rasm.zarr\n"
     ]
    }
   ],
   "source": [
    "!ls data/*zarr\n",
    "!du -h data/*zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x7fe5c6616828>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zarr\n",
    "compressor = zarr.Blosc(clevel=2, shuffle=-1)\n",
    "ds.to_zarr('./data/rasm_compressed.zarr', mode='w', encoding={var: {'compressor': compressor} for var in ds.variables})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/rasm_compressed.zarr:\n",
      "Tair  time  xc\tyc\n",
      "\n",
      "data/rasm.zarr:\n",
      "Tair  time  xc\tyc\n",
      "352K\tdata/rasm.zarr/yc\n",
      "16K\tdata/rasm.zarr/time\n",
      "336K\tdata/rasm.zarr/xc\n",
      "7.7M\tdata/rasm.zarr/Tair\n",
      "8.4M\tdata/rasm.zarr\n",
      "360K\tdata/rasm_compressed.zarr/yc\n",
      "16K\tdata/rasm_compressed.zarr/time\n",
      "344K\tdata/rasm_compressed.zarr/xc\n",
      "7.8M\tdata/rasm_compressed.zarr/Tair\n",
      "8.5M\tdata/rasm_compressed.zarr\n"
     ]
    }
   ],
   "source": [
    "!ls data/*zarr\n",
    "!du -h data/*zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interoperability\n",
    "\n",
    "Xarray objects include exports methods that allow users to transform data from the Xarray data model to other data models such as Pandas, Iris, and CDMS. \n",
    "\n",
    "Below is a quick example of how to export a time series from Xarray to Pandas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "1980-09-16 12:00:00    -3.419416\n",
       "1980-10-17 00:00:00   -15.496765\n",
       "1980-11-16 12:00:00   -26.294163\n",
       "1980-12-17 00:00:00   -29.829660\n",
       "1981-01-17 00:00:00   -21.887778\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_series = ds.isel(x=100, y=100)['Tair'].to_pandas()\n",
    "t_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_series.to_csv('data/rasm_point.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xarray]",
   "language": "python",
   "name": "conda-env-xarray-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
