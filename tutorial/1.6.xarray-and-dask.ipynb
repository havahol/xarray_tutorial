{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xarray and parallel computing with dask\n",
    "\n",
    "xarray integrates with dask to support parallel computations and streaming computation on datasets that don’t fit into memory.\n",
    "\n",
    "### Outline\n",
    "- reading and writing data\n",
    "- automatic parallelization\n",
    "- dask schedulers and deployments\n",
    "\n",
    "### Tutorial Duriation\n",
    "10 minutes\n",
    "\n",
    "### Going Further\n",
    "\n",
    "- Xarray's Documentation on using dask: http://xarray.pydata.org/en/latest/dask.html\n",
    "- Dask's Documentation: http://dask.pydata.org/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask\n",
    "\n",
    "Dask is a flexible parallel computing library for analytic computing.\n",
    "\n",
    "Dask is composed of two components:\n",
    "\n",
    "- Dynamic task scheduling optimized for computation. This is similar to Airflow, Luigi, Celery, or Make, but optimized for interactive computational workloads.\n",
    "- “Big Data” collections like parallel arrays, dataframes, and lists that extend common interfaces like NumPy, Pandas, or Python iterators to larger-than-memory or distributed environments. These parallel collections run on top of the dynamic task schedulers.\n",
    "\n",
    "![](images/collections-schedulers.png)\n",
    "\n",
    "\n",
    "Dask works by constructing \"task graphs\"\n",
    "\n",
    "![](images/transpose.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing data\n",
    "\n",
    "The usual way to create a dataset filled with dask arrays is to load the data from a netCDF file or files. You can do this by supplying a chunks argument to open_dataset() or using the open_mfdataset() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "np.warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:44147\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>1</li>\n",
       "  <li><b>Memory: </b>4.14 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:44147' processes=1 cores=1>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use dask's distributed scheduler for now\n",
    "# (see the last section of this notebook for more details)\n",
    "from distributed import Client, progress\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 36, x: 275, y: 205)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1980-09-16T12:00:00 1980-10-17 ...\n",
       "    xc       (y, x) float64 dask.array<shape=(205, 275), chunksize=(205, 275)>\n",
       "    yc       (y, x) float64 dask.array<shape=(205, 275), chunksize=(205, 275)>\n",
       "Dimensions without coordinates: x, y\n",
       "Data variables:\n",
       "    Tair     (time, y, x) float64 dask.array<shape=(36, 205, 275), chunksize=(10, 205, 275)>\n",
       "Attributes:\n",
       "    title:                     /workspace/jhamman/processed/R1002RBRxaaa01a/l...\n",
       "    institution:               U.W.\n",
       "    source:                    RACM R1002RBRxaaa01a\n",
       "    output_frequency:          daily\n",
       "    output_mode:               averaged\n",
       "    convention:                CF-1.4\n",
       "    references:                Based on the initial model of Liang et al., 19...\n",
       "    comment:                   Output from the Variable Infiltration Capacity...\n",
       "    nco_openmp_thread_number:  1\n",
       "    NCO:                       \"4.6.0\"\n",
       "    history:                   Tue Dec 27 14:15:22 2016: ncatted -a dimension..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = xr.open_dataset('./data/rasm.nc', chunks={'time': 10})  # this actually loads data using xr.open_dataset\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.array<open_dataset-e1fb31316899b622cebbb3cfb4f33f17Tair, shape=(36, 205, 275), dtype=float64, chunksize=(10, 205, 275)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xarray is now using dask arrays under the hood\n",
    "ds['Tair'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Xarray operations using dask are now lazy\n",
    "t_range = (ds['Tair'].resample(time='AS').max('time') -\n",
    "           ds['Tair'].resample(time='AS').min('time')).mean('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Drawing dask graphs requires the `graphviz` python library and the `graphviz` system library to be installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/xarray/lib/python3.6/site-packages/dask/utils.py\u001b[0m in \u001b[0;36mimport_required\u001b[0;34m(mod_name, error_msg)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xarray/lib/python3.6/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xarray/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xarray/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xarray/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c31a640ddc55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/xarray/lib/python3.6/site-packages/dask/base.py\u001b[0m in \u001b[0;36mvisualize\u001b[0;34m(self, filename, format, optimize_graph, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \"\"\"\n\u001b[1;32m     87\u001b[0m         return visualize(self, filename=filename, format=format,\n\u001b[0;32m---> 88\u001b[0;31m                          optimize_graph=optimize_graph, **kwargs)\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xarray/lib/python3.6/site-packages/dask/base.py\u001b[0m in \u001b[0;36mvisualize\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mhttp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlatest\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \"\"\"\n\u001b[0;32m--> 445\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdot_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mydask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xarray/lib/python3.6/site-packages/dask/dot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m graphviz = import_required(\"graphviz\", \"Drawing dask graphs requires the \"\n\u001b[0m\u001b[1;32m     13\u001b[0m                                        \u001b[0;34m\"`graphviz` python library and the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                        \u001b[0;34m\"`graphviz` system library to be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xarray/lib/python3.6/site-packages/dask/utils.py\u001b[0m in \u001b[0;36mimport_required\u001b[0;34m(mod_name, error_msg)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Drawing dask graphs requires the `graphviz` python library and the `graphviz` system library to be installed."
     ]
    }
   ],
   "source": [
    "t_range.data.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = t_range.persist()\n",
    "progress(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic parallelization\n",
    "\n",
    "Almost all of xarray’s built-in operations work on dask arrays. If you want to use a function that isn’t wrapped by xarray, one option is to extract dask arrays from xarray objects (.data) and use dask directly.\n",
    "\n",
    "Another option is to use xarray’s apply_ufunc(), which can automate embarrassingly parallel “map” type operations where a functions written for processing NumPy arrays should be repeatedly applied to xarray objects containing dask arrays. It works similarly to `dask.array.map_blocks()` and `dask.array.atop()`, but without requiring an intermediate layer of abstraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bottleneck\n",
    "\n",
    "def covariance_gufunc(x, y):\n",
    "    return ((x - x.mean(axis=-1, keepdims=True))\n",
    "            * (y - y.mean(axis=-1, keepdims=True))).mean(axis=-1)\n",
    "\n",
    "def pearson_correlation_gufunc(x, y):\n",
    "    return covariance_gufunc(x, y) / (x.std(axis=-1) * y.std(axis=-1))\n",
    "\n",
    "def spearman_correlation_gufunc(x, y):\n",
    "    x_ranks = bottleneck.rankdata(x, axis=-1)\n",
    "    y_ranks = bottleneck.rankdata(y, axis=-1)\n",
    "    return pearson_correlation_gufunc(x_ranks, y_ranks)\n",
    "\n",
    "def spearman_correlation(x, y, dim):\n",
    "    return xr.apply_ufunc(\n",
    "        spearman_correlation_gufunc, x, y,\n",
    "        input_core_dims=[[dim], [dim]],\n",
    "        dask='parallelized',\n",
    "        output_dtypes=[float])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['Tair'].roll(time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.chunk({'x': 25, 'y': 25, 'time': -1})  # rechunk this dataset\n",
    "\n",
    "# create some toy data using our dataset\n",
    "x = ds['Tair']\n",
    "y = ds['Tair'].roll(time=1)  # lag the air temp data by one month\n",
    "y['time'] = x['time']  # reset the index \n",
    "\n",
    "\n",
    "# calculate the spearman correlation\n",
    "corr = spearman_correlation(x, y, 'time')\n",
    "corr = corr.where(corr < 1)  # make sure nans are masked properly\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dask schedulers and deployments\n",
    "\n",
    "Dask provides 4 different mechanisms for executing dask task graphs.\n",
    "\n",
    "- `dask.threaded.get`: a scheduler backed by a thread pool\n",
    "- `dask.multiprocessing.get`: a scheduler backed by a process pool\n",
    "- `dask.get`: a synchronous scheduler, good for debugging\n",
    "- `distributed.Client.get`: a distributed scheduler for executing graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.multiprocessing\n",
    "dask.config.set(scheduler='processes')  # overwrite default with multiprocessing scheduler\n",
    "\n",
    "# or\n",
    "\n",
    "from distributed import Client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lots more! \n",
    "\n",
    "- Setting up dask: http://dask.pydata.org/en/latest/setup.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xarray]",
   "language": "python",
   "name": "conda-env-xarray-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
